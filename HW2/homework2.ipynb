{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CS344 Homework 2\n",
    "##Myungha Kim\n",
    "##March 8th, 2019\n",
    "##Problem 1: Build a spam filter based on Paul Graham’s A Plan for Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem 1: Build a spam filter based on Paul Graham’s A Plan for Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Hashtable:\n",
      "\n",
      "Spam\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This program takes in the sample text and test if it is a spam or not based on the data from\n",
    "hash tables of words from spam corpus and non-spam corpus & calculated probability for each word being spam\n",
    "'''\n",
    "\n",
    "\n",
    "def Hash(spam_corpus, ham_corpus):\n",
    "    spam = {}  # key as token; value as the number of occurence\n",
    "    not_spam = {}\n",
    "    token = []\n",
    "    ngood = 0\n",
    "    nbad = 0\n",
    "\n",
    "    # 1st hash table for spam\n",
    "    for msg in spam_corpus:\n",
    "        nbad += 1\n",
    "        for wd in msg:\n",
    "            if wd in spam:\n",
    "                spam[wd] += 1\n",
    "            else:\n",
    "                spam[wd] = 1\n",
    "            if wd not in token:\n",
    "                token.append(wd)\n",
    "\n",
    "    # 2nd hash table for not_spam\n",
    "    for msg in ham_corpus:\n",
    "        ngood += 1\n",
    "        for wd in msg:\n",
    "            if wd in not_spam:\n",
    "                not_spam[wd] += 1\n",
    "            else:\n",
    "                not_spam[wd] = 1\n",
    "            if wd not in token:\n",
    "                token.append(wd)\n",
    "\n",
    "    # 3rd hash table - probability\n",
    "    prob = {}\n",
    "    for wd in token:\n",
    "        if wd in not_spam:\n",
    "            g = 2 * not_spam[wd]\n",
    "        else:\n",
    "            g = 0\n",
    "        if wd in spam:\n",
    "            b = spam[wd]\n",
    "        else:\n",
    "            b = 0\n",
    "        if g + b > 1:\n",
    "            prob[wd] = max(0.01, min(0.99, min(1.0, b/nbad) / (min(1.0, g/ngood) + min(1.0, b/nbad))))\n",
    "        else:\n",
    "            prob[wd] = 0\n",
    "    print(\"Probability Hashtable:\\n\")\n",
    "    return prob\n",
    "\n",
    "def SpamCheck(text, filt):\n",
    "    product = 1\n",
    "    comp_product = 1\n",
    "\n",
    "    for wd in text:\n",
    "        if wd in filt:\n",
    "            product *= filt[wd]\n",
    "            comp_product *= 1 - filt[wd]\n",
    "        elif wd not in filt:\n",
    "            filt[wd] = 0.4\n",
    "    marginal = product + comp_product\n",
    "    Bayes = product / marginal\n",
    "    if Bayes > 0.9:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Hard-coded SPAM/HAM corpus\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "sample_text = [\"I\", \"am\", \"spam\", \"yes\", \"i\", \"am\"]\n",
    "\n",
    "spam_filter = Hash(spam_corpus, ham_corpus)\n",
    "if SpamCheck(sample_text, spam_filter):\n",
    "    print(\"Spam\")\n",
    "else:\n",
    "    print(\"Not spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Q. Graham argues that this is a Bayesian approach to SPAM. What makes it Bayesian?\n",
    "Graham argues that this is a Bayesian approach to filter spam emails because the algorithm decides if the email is spam or not based on the given probability of each word in the email being spam or not. With the probability of each word (token) being spam or not, the probability of the email being spam or not via Bayesian statistical model which is the kernel / marginal at the end of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem 2: Do the following exercises based on the Bayesian network shown in Figure 14.12a\n",
    "##Part a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.aima.probability import BayesNet, enumeration_ask, elimination_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14_12 - Weather\n",
    "weatherA = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.10, F: 0.50}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part b.\n",
    "the number of independent values in the full joint probability distribution for this domain -> 2^4 = 16\n",
    "\n",
    "Part c.\n",
    "The number of independent values in the Bayesian network for this domain -> 9, counting connected bayesian networks shown in the figure\n",
    "\n",
    "Part d.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P(Cloudy)\n",
    "print('P(Cloudy)')\n",
    "print(\"Enumeration-ask -> \" + enumeration_ask('Cloudy', dict(), weatherA).show_approx())\n",
    "\n",
    "# Compute P(Sprinkler | cloudy)\n",
    "print('\\nP(Sprinkler | cloudy)')\n",
    "print(\"Enumeration-ask -> \" + enumeration_ask('Sprinkler', dict(Cloudy=T), weatherA).show_approx())\n",
    "\n",
    "# Compute P(Cloudy| the sprinkler is running and it’s not raining)\n",
    "print('\\nP (Cloudy | sprinker and -rain')\n",
    "print(\"Enumeration-ask -> \" + enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), weatherA).show_approx())\n",
    "\n",
    "# Compute P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
    "print('\\nP (WetGrass | cloudy and sprinkler and rain')\n",
    "print(\"Enumeration-ask -> \" + enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), weatherA).show_approx())\n",
    "\n",
    "# Compute P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
    "print('\\nP (WetGrass | cloudy and sprinkler and rain')\n",
    "print(\"Enumeration-ask -> \" + enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), weatherA).show_approx())\n",
    "\n",
    "# Compute P(Cloudy | the grass is not wet)\n",
    "print('\\nP (Cloudy | -wet grass)')\n",
    "print(\"Enumeration-ask -> \" + enumeration_ask('Cloudy', dict(WetGrass=F), weatherA).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hand-worked derivations\n",
    "\n",
    "###i. P(Cloudy) = <0.5, 0.5> ii. P(Sprinker | cloudy) = <0.1, 0.9> iii. P(Cloudy| sprinker ^ -rain) = alpha * <0.5 * 0.1 * 0.2, 0.5 * 0.5 * 0.8> = alpha * <0.01, 0.2> = <0.0476, 0.9524> iv. P(WetGrass | cloudy ^ sprinkler ^ rain) = alpha * <0.5 * 0.1 * 0.8 * 0.99, 0.5 * 0.1 * 0.8 * 0.01> = alpha * <0.99, 0.01> = <0.99, 0.01>\n",
    "v. P(Cloudy|-wetgrass) = alpha * sum( P(Cloudy ^ sprinkler ^ rain ^ -wetgrass) ) = alpha * sum( P(Cloudy) * P(sprinkler ^ rain ^ -wetgrass | Cloudy) ) = alpha * <0.5 * 0.1 * 0.8 * 0.01 + 0.5 * 0.1 * 0.2 * 0.1 + 0.5 * 0.9 * 0.8 * 0.1 + 0.5 * 0.9 * 0.2 * 1.00, 0.5 * 0.5 * 0.2 * 0.01 + 0.5 * 0.5 * 0.8 * 0.1 + 0.5 * 0.5 * 0.2 * 0.1 + 0.5 * 0.5 * 0.8 * 1.00> = alpha * <0.1274, 0.2255> = <0.361, 0.639>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
